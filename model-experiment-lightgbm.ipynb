{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:11.990668Z","iopub.execute_input":"2025-04-30T16:57:11.991059Z","iopub.status.idle":"2025-04-30T16:57:13.316079Z","shell.execute_reply.started":"2025-04-30T16:57:11.991030Z","shell.execute_reply":"2025-04-30T16:57:13.315048Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install dagshub mlflow --quiet\n!pip install imbalanced-learn==0.11.0 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:13.318530Z","iopub.execute_input":"2025-04-30T16:57:13.319038Z","iopub.status.idle":"2025-04-30T16:57:24.503623Z","shell.execute_reply.started":"2025-04-30T16:57:13.319009Z","shell.execute_reply":"2025-04-30T16:57:24.501784Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import dagshub\nimport mlflow\n\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nimport mlflow\nimport mlflow.sklearn\nimport xgboost as xgb\nfrom category_encoders import WOEEncoder\nimport warnings\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\nfrom imblearn.pipeline import Pipeline as ImbPipeline  # âœ… Corrected import\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n# import shap\nimport mlflow.data\nfrom mlflow.data.pandas_dataset import PandasDataset\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:24.505860Z","iopub.execute_input":"2025-04-30T16:57:24.506361Z","iopub.status.idle":"2025-04-30T16:57:31.917018Z","shell.execute_reply.started":"2025-04-30T16:57:24.506306Z","shell.execute_reply":"2025-04-30T16:57:31.915170Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import mlflow\nfrom dagshub import dagshub_logger\nimport os\n\n# Set tracking URI manually\nmlflow.set_tracking_uri(\"https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow\")\n\n# Use your DagsHub credentials\nos.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"nkikn21\"\nos.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"90ec7031365aea1b6ca271f4236c194e530973c8\"\n\n# Optional: set registry if you're using model registry\nmlflow.set_registry_uri(\"https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:31.918303Z","iopub.execute_input":"2025-04-30T16:57:31.919108Z","iopub.status.idle":"2025-04-30T16:57:31.927527Z","shell.execute_reply.started":"2025-04-30T16:57:31.919071Z","shell.execute_reply":"2025-04-30T16:57:31.925639Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.width', None)        \npd.set_option('display.expand_frame_repr', False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:31.930507Z","iopub.execute_input":"2025-04-30T16:57:31.931052Z","iopub.status.idle":"2025-04-30T16:57:31.955580Z","shell.execute_reply.started":"2025-04-30T16:57:31.930950Z","shell.execute_reply":"2025-04-30T16:57:31.954101Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n# test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n# test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:57:31.957165Z","iopub.execute_input":"2025-04-30T16:57:31.957703Z","iopub.status.idle":"2025-04-30T16:58:04.480159Z","shell.execute_reply.started":"2025-04-30T16:57:31.957670Z","shell.execute_reply":"2025-04-30T16:58:04.479093Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_joined = train_transaction.merge(train_identity, on=\"TransactionID\", how=\"left\")\n# test_joined = test_transaction.merge(test_identity, on=\"TransactionID\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:04.481197Z","iopub.execute_input":"2025-04-30T16:58:04.481509Z","iopub.status.idle":"2025-04-30T16:58:05.433110Z","shell.execute_reply.started":"2025-04-30T16:58:04.481485Z","shell.execute_reply":"2025-04-30T16:58:05.432060Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_joined['TransactionDay'] = train_joined['TransactionDT'] // (24*60*60)\n# test_joined['TransactionDay'] = test_joined['TransactionDT'] // (24*60*60)\ncutoff_day = train_joined['TransactionDay'].max() - 30  # last 30 days for validation\n\ntrain_data = train_joined[train_joined['TransactionDay'] <= cutoff_day]\nval_data = train_joined[train_joined['TransactionDay'] > cutoff_day]\n\nX_train = train_data.drop(columns=['isFraud', 'TransactionID'])\ny_train = train_data['isFraud']\n\nX_val = val_data.drop(columns=['isFraud', 'TransactionID'])\ny_val = val_data['isFraud']\n\n# X_test = test_joined.drop(columns=['TransactionID', 'isFraud'], errors='ignore')  # Ignore errors in case 'isFraud' isn't in test_joined\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:05.434186Z","iopub.execute_input":"2025-04-30T16:58:05.434497Z","iopub.status.idle":"2025-04-30T16:58:07.056344Z","shell.execute_reply.started":"2025-04-30T16:58:05.434464Z","shell.execute_reply":"2025-04-30T16:58:07.055018Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\ncat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:07.057584Z","iopub.execute_input":"2025-04-30T16:58:07.057901Z","iopub.status.idle":"2025-04-30T16:58:09.518654Z","shell.execute_reply.started":"2025-04-30T16:58:07.057877Z","shell.execute_reply":"2025-04-30T16:58:09.517661Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"s = X_train[cat_cols].nunique()\n\nthreshold = 3\n\nwoe_columns = list(s[s > threshold].index)\none_hot_columns = list(s[s <= threshold].index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:09.519907Z","iopub.execute_input":"2025-04-30T16:58:09.520317Z","iopub.status.idle":"2025-04-30T16:58:10.121115Z","shell.execute_reply.started":"2025-04-30T16:58:09.520280Z","shell.execute_reply":"2025-04-30T16:58:10.120002Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"import mlflow\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass Cleaning(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, woe_columns, one_hot_columns, num_cols, log_mlflow=False, null_threshold=0.8):\n        self.woe_columns = woe_columns\n        self.one_hot_columns = one_hot_columns\n        self.num_cols = num_cols\n        self.log_mlflow = log_mlflow\n        self.null_threshold = null_threshold\n\n    def fit(self, X, y=None):\n        # Drop columns with more than threshold% missing values\n        null_frac = X.isnull().mean()\n        self.to_drop = null_frac[null_frac > self.null_threshold].index.tolist()\n\n        # Fill strategies for remaining columns\n        self.woe_columns_fill_na = X[self.woe_columns].mode().T[0].to_dict()\n        self.one_hot_columns_fill_na = X[self.one_hot_columns].mode().T[0].to_dict()\n        self.num_cols_fill_na = X[self.num_cols].median().to_dict()\n\n        # MLflow logging\n        if self.log_mlflow:\n            experiment_name = 'LGBM_Training'\n            run_name = 'LGBM_Cleaning'\n            \n            mlflow.set_experiment(experiment_name)\n            mlflow.start_run(run_name=run_name)\n\n            mlflow.log_param(\"cat_cols_handling\", \"mode\")\n            mlflow.log_param(\"num_cols_handling\", \"median\")\n            mlflow.log_param(\"dropped_cols_threshold\", self.null_threshold)\n            mlflow.log_param(\"dropped_columns\", self.to_drop)\n\n            mlflow.end_run()\n        \n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n\n        # Drop columns identified during fit\n        X_transformed = X_transformed.drop(columns=self.to_drop, errors='ignore')\n\n        # Fill WOE columns\n        for col in self.woe_columns:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.woe_columns_fill_na.get(col))\n\n        # Fill one-hot columns\n        for col in self.one_hot_columns:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.one_hot_columns_fill_na.get(col))\n\n        # Fill numeric columns\n        for col in self.num_cols:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.num_cols_fill_na.get(col))\n\n        return X_transformed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:10.122477Z","iopub.execute_input":"2025-04-30T16:58:10.122873Z","iopub.status.idle":"2025-04-30T16:58:10.134524Z","shell.execute_reply.started":"2025-04-30T16:58:10.122838Z","shell.execute_reply":"2025-04-30T16:58:10.133479Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport mlflow\n\nclass FeatureEngineering(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, woe_columns=None, one_hot_columns=None, woe_mappings=None, woe_columns_fill_na=None, log_mlflow=False):\n        self.woe_columns = woe_columns\n        self.one_hot_columns = one_hot_columns\n        self.woe_mappings = woe_mappings\n        self.woe_columns_fill_na = woe_columns_fill_na\n        self.log_mlflow = log_mlflow\n\n    def fit(self, X, y=None):\n        # Assign default dicts if None (safe to do here)\n        self.woe_mappings_ = self.woe_mappings or {}\n        self.woe_columns_fill_na_ = self.woe_columns_fill_na or {}\n\n        # Optional: make sure columns exist\n        self.woe_columns_ = [col for col in self.woe_columns if col in X.columns]\n        self.one_hot_columns_ = [col for col in self.one_hot_columns if col in X.columns]\n\n        # Log to MLflow\n        if self.log_mlflow:\n            experiment_name = \"LGBM_Training\"\n            run_name = \"LGBM_Feature_Engineering\"\n            mlflow.set_experiment(experiment_name)\n            with mlflow.start_run(run_name=run_name):\n                mlflow.log_param(\"woe_columns\", self.woe_columns_)\n                mlflow.log_param(\"one_hot_columns\", self.one_hot_columns_)\n\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n\n        # WOE encoding\n        for col in self.woe_columns_:\n            mapping = self.woe_mappings_.get(col, {})\n            default_val = mapping.get(self.woe_columns_fill_na_.get(col), 0)\n            new_col = f'{col}_woe'\n            X_transformed[new_col] = X_transformed[col].map(mapping).fillna(default_val)\n            X_transformed.drop(columns=col, inplace=True)\n\n        # One-hot encoding\n        X_transformed = pd.get_dummies(\n            X_transformed, \n            columns=self.one_hot_columns_, \n            drop_first=True, \n            dummy_na=True,\n            dtype=int\n        )\n\n        return X_transformed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:10.135560Z","iopub.execute_input":"2025-04-30T16:58:10.136090Z","iopub.status.idle":"2025-04-30T16:58:10.163992Z","shell.execute_reply.started":"2025-04-30T16:58:10.136050Z","shell.execute_reply":"2025-04-30T16:58:10.162847Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"class FeatureSelection(BaseEstimator, TransformerMixin):\n    def __init__(self, model, correlation_threshold=0.8, n_features_to_select=30, log_mlflow=False):\n        self.model = model\n        self.correlation_threshold = correlation_threshold\n        self.n_features_to_select = n_features_to_select\n        self.log_mlflow = log_mlflow\n\n    def fit(self, X, y=None):\n        # Step 1: Remove highly correlated features\n        corr_matrix = X.corr().abs()\n        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n        self.to_drop = [column for column in upper.columns if any(upper[column] > self.correlation_threshold)]\n    \n        # Step 2: Run RFE to select top N features\n        self.rfe = RFE(self.model, n_features_to_select=self.n_features_to_select)\n        self.rfe.fit(X, y)\n    \n        all_rfe_features = X.columns[self.rfe.support_].tolist()\n    \n        # Step 3: Final selected features = RFE features minus highly correlated\n        self.selected_features = [col for col in all_rfe_features if col not in self.to_drop]\n    \n        # Step 4: Log to MLflow if enabled\n        if self.log_mlflow:\n            experiment_name = 'LGBM_Training'\n            run_name = 'LGBM_Feature_Selection'\n            \n            mlflow.set_experiment(experiment_name)\n            mlflow.start_run(run_name=run_name)\n            \n            mlflow.log_param(\"RFE_all_features\", all_rfe_features)\n            mlflow.log_param(\"Highly_correlated_dropped\", self.to_drop)\n            mlflow.log_param(\"Selected_features\", self.selected_features)\n\n            mlflow.end_run()\n    \n        return self\n\n\n    def transform(self, X):\n        return X[self.selected_features]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:10.165127Z","iopub.execute_input":"2025-04-30T16:58:10.165445Z","iopub.status.idle":"2025-04-30T16:58:10.187955Z","shell.execute_reply.started":"2025-04-30T16:58:10.165422Z","shell.execute_reply":"2025-04-30T16:58:10.186730Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom lightgbm import LGBMClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Create the pipeline with LightGBM\nimb_pipeline = ImbPipeline(steps=[\n    ('undersampler', RandomUnderSampler(random_state=42, sampling_strategy=0.4)),\n    \n    ('cleaning', Cleaning(\n        woe_columns=woe_columns, \n        one_hot_columns=one_hot_columns, \n        num_cols=num_cols, \n        log_mlflow=True\n    )),\n    \n    ('feature_engineering', FeatureEngineering(\n        woe_columns=woe_columns, \n        one_hot_columns=one_hot_columns, \n        log_mlflow=True\n    )),\n    \n    ('feature_selection', FeatureSelection(\n        model=LGBMClassifier(\n            objective='binary',\n            boosting_type='gbdt',\n            n_jobs=-1,\n            random_state=42\n        ),\n        n_features_to_select=30, \n        log_mlflow=True\n    )),\n    \n    ('scaler', StandardScaler()),\n    \n    ('classifier', LGBMClassifier(\n        objective='binary',\n        boosting_type='gbdt',\n        n_jobs=-1,\n        random_state=42\n    ))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:10.192181Z","iopub.execute_input":"2025-04-30T16:58:10.192563Z","iopub.status.idle":"2025-04-30T16:58:13.258232Z","shell.execute_reply.started":"2025-04-30T16:58:10.192534Z","shell.execute_reply":"2025-04-30T16:58:13.257071Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\n\n# Optional: convert object columns to category if using categorical features\nfor col in X_train.select_dtypes(include='object').columns:\n    X_train[col] = X_train[col].astype('category')\n    X_val[col] = X_val[col].astype('category')\n\n# Define LGBM model\nlgbm = LGBMClassifier(\n    objective='binary',\n    random_state=42,\n    n_jobs=-1,\n    verbose=-1\n)\n\n# Define parameter grid (small for demo; expand as needed)\nparam_dist = {\n    'n_estimators': np.random.randint(100, 501, size=5),  # 100 random ints between 100 and 500\n    'max_depth': np.random.randint(3, 12, size=5),         # random ints from 3 to 11\n    'learning_rate': np.random.uniform(0.01, 0.3, size=5), # float values between 0.01 and 0.3\n}\n\n# Randomized search CV\nrandom_search = RandomizedSearchCV(\n    estimator=xgb,\n    param_distributions=param_dist,\n    n_iter=30,  # Number of random combinations to try\n    scoring='roc_auc',\n    cv=2,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1\n)\n# Fit\nrandom_search.fit(X_train, y_train)\n\n# Results\nprint(\"Best Parameters:\", grid_srandom_searchearch.best_params_)\nprint(\"Best ROC AUC Score (CV):\", grid_search.best_score_)\n\n# Optionally use the best model\nbest_lgbm = grid_search.best_estimator_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:13.259478Z","iopub.execute_input":"2025-04-30T16:58:13.260439Z","iopub.status.idle":"2025-04-30T16:58:15.380287Z","shell.execute_reply.started":"2025-04-30T16:58:13.260408Z","shell.execute_reply":"2025-04-30T16:58:15.378200Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_402/907588366.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \"\"\"\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;34m\"estimator should be an estimator implementing 'fit' method, %r was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <module 'xgboost' from '/usr/local/lib/python3.11/dist-packages/xgboost/__init__.py'> was passed"],"ename":"TypeError","evalue":"estimator should be an estimator implementing 'fit' method, <module 'xgboost' from '/usr/local/lib/python3.11/dist-packages/xgboost/__init__.py'> was passed","output_type":"error"}],"execution_count":15},{"cell_type":"markdown","source":"**Model_v1**","metadata":{}},{"cell_type":"code","source":"# imb_pipeline.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:15.381277Z","iopub.status.idle":"2025-04-30T16:58:15.381780Z","shell.execute_reply.started":"2025-04-30T16:58:15.381548Z","shell.execute_reply":"2025-04-30T16:58:15.381570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# experiment_name = 'LGBM_Training'\n# run_name = 'Model_v1'\n\n# mlflow.set_experiment(experiment_name)\n# mlflow.start_run(run_name=run_name)\n\n# mlflow.sklearn.log_model(imb_pipeline, \"LGBM_pipeline\")\n\n# # Train the model\n# # imb_pipeline.fit(X_train, y_train)\n\n# # Log metrics (e.g., AUC, F1-score, etc.)\n# y_pred = imb_pipeline.predict(X_val)\n# y_pred_proba = imb_pipeline.predict_proba(X_val)[:, 1]\n\n# auc_score = roc_auc_score(y_val, y_pred_proba)\n# f1_score_val = f1_score(y_val, y_pred)\n# precision_score_val = precision_score(y_val, y_pred)\n# recall_score_val = recall_score(y_val, y_pred)\n\n# mlflow.log_metric(\"AUC\", auc_score)\n# mlflow.log_metric(\"F1_Score\", f1_score_val)\n# mlflow.log_metric(\"Precision\", precision_score_val)\n# mlflow.log_metric(\"Recall\", recall_score_val)\n\n# # Log model parameters\n# mlflow.log_param(\"RandomUnderSampler_Sampling_Strategy\", 0.4)\n# mlflow.log_param(\"Classifier\", \"XGBClassifier\")\n\n# mlflow.end_run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:58:15.384055Z","iopub.status.idle":"2025-04-30T16:58:15.384588Z","shell.execute_reply.started":"2025-04-30T16:58:15.384308Z","shell.execute_reply":"2025-04-30T16:58:15.384330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
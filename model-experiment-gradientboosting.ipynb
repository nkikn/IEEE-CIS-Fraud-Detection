{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:11:35.722172Z","iopub.execute_input":"2025-04-30T15:11:35.722550Z","iopub.status.idle":"2025-04-30T15:11:38.265217Z","shell.execute_reply.started":"2025-04-30T15:11:35.722518Z","shell.execute_reply":"2025-04-30T15:11:38.264152Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install dagshub mlflow --quiet\n!pip install imbalanced-learn==0.11.0 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:11:43.055162Z","iopub.execute_input":"2025-04-30T15:11:43.055500Z","iopub.status.idle":"2025-04-30T15:12:04.076373Z","shell.execute_reply.started":"2025-04-30T15:11:43.055477Z","shell.execute_reply":"2025-04-30T15:12:04.075078Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.0/700.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import dagshub\nimport mlflow\n\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nimport mlflow\nimport mlflow.sklearn\nimport xgboost as xgb\nfrom category_encoders import WOEEncoder\nimport warnings\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\nfrom imblearn.pipeline import Pipeline as ImbPipeline  # ✅ Corrected import\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nimport shap\nimport mlflow.data\nfrom mlflow.data.pandas_dataset import PandasDataset\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:04.078624Z","iopub.execute_input":"2025-04-30T15:12:04.078979Z","iopub.status.idle":"2025-04-30T15:12:20.258040Z","shell.execute_reply.started":"2025-04-30T15:12:04.078953Z","shell.execute_reply":"2025-04-30T15:12:20.257065Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import mlflow\nfrom dagshub import dagshub_logger\nimport os\n\n# Set tracking URI manually\nmlflow.set_tracking_uri(\"https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow\")\n\n# Use your DagsHub credentials\nos.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"nkikn21\"\nos.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"90ec7031365aea1b6ca271f4236c194e530973c8\"\n\n# Optional: set registry if you're using model registry\nmlflow.set_registry_uri(\"https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:20.258967Z","iopub.execute_input":"2025-04-30T15:12:20.259530Z","iopub.status.idle":"2025-04-30T15:12:20.265540Z","shell.execute_reply.started":"2025-04-30T15:12:20.259503Z","shell.execute_reply":"2025-04-30T15:12:20.264420Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.width', None)        \npd.set_option('display.expand_frame_repr', False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:20.267463Z","iopub.execute_input":"2025-04-30T15:12:20.267925Z","iopub.status.idle":"2025-04-30T15:12:20.308608Z","shell.execute_reply.started":"2025-04-30T15:12:20.267885Z","shell.execute_reply":"2025-04-30T15:12:20.306854Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n# test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n# test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:20.309953Z","iopub.execute_input":"2025-04-30T15:12:20.310222Z","iopub.status.idle":"2025-04-30T15:12:53.247080Z","shell.execute_reply.started":"2025-04-30T15:12:20.310201Z","shell.execute_reply":"2025-04-30T15:12:53.245781Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_joined = train_transaction.merge(train_identity, on=\"TransactionID\", how=\"left\")\n# test_joined = test_transaction.merge(test_identity, on=\"TransactionID\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:53.249649Z","iopub.execute_input":"2025-04-30T15:12:53.250849Z","iopub.status.idle":"2025-04-30T15:12:54.319572Z","shell.execute_reply.started":"2025-04-30T15:12:53.250792Z","shell.execute_reply":"2025-04-30T15:12:54.315740Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_joined['TransactionDay'] = train_joined['TransactionDT'] // (24*60*60)\n# test_joined['TransactionDay'] = test_joined['TransactionDT'] // (24*60*60)\ncutoff_day = train_joined['TransactionDay'].max() - 30  # last 30 days for validation\n\ntrain_data = train_joined[train_joined['TransactionDay'] <= cutoff_day]\nval_data = train_joined[train_joined['TransactionDay'] > cutoff_day]\n\nX_train = train_data.drop(columns=['isFraud', 'TransactionID'])\ny_train = train_data['isFraud']\n\nX_val = val_data.drop(columns=['isFraud', 'TransactionID'])\ny_val = val_data['isFraud']\n\n# X_test = test_joined.drop(columns=['TransactionID', 'isFraud'], errors='ignore')  # Ignore errors in case 'isFraud' isn't in test_joined\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:54.321685Z","iopub.execute_input":"2025-04-30T15:12:54.323835Z","iopub.status.idle":"2025-04-30T15:12:56.446425Z","shell.execute_reply.started":"2025-04-30T15:12:54.323694Z","shell.execute_reply":"2025-04-30T15:12:56.445548Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\ncat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:12:56.447580Z","iopub.execute_input":"2025-04-30T15:12:56.447854Z","iopub.status.idle":"2025-04-30T15:13:02.529939Z","shell.execute_reply.started":"2025-04-30T15:12:56.447832Z","shell.execute_reply":"2025-04-30T15:13:02.525761Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"s = X_train[cat_cols].nunique()\n\nthreshold = 3\n\nwoe_columns = list(s[s > threshold].index)\none_hot_columns = list(s[s <= threshold].index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:02.535086Z","iopub.execute_input":"2025-04-30T15:13:02.536025Z","iopub.status.idle":"2025-04-30T15:13:03.420123Z","shell.execute_reply.started":"2025-04-30T15:13:02.535967Z","shell.execute_reply":"2025-04-30T15:13:03.418936Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"import mlflow\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass Cleaning(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, woe_columns, one_hot_columns, num_cols, log_mlflow=False, null_threshold=0.8):\n        self.woe_columns = woe_columns\n        self.one_hot_columns = one_hot_columns\n        self.num_cols = num_cols\n        self.log_mlflow = log_mlflow\n        self.null_threshold = null_threshold\n\n    def fit(self, X, y=None):\n        # Drop columns with more than threshold% missing values\n        null_frac = X.isnull().mean()\n        self.to_drop = null_frac[null_frac > self.null_threshold].index.tolist()\n\n        # Fill strategies for remaining columns\n        self.woe_columns_fill_na = X[self.woe_columns].mode().T[0].to_dict()\n        self.one_hot_columns_fill_na = X[self.one_hot_columns].mode().T[0].to_dict()\n        self.num_cols_fill_na = X[self.num_cols].median().to_dict()\n\n        # MLflow logging\n        if self.log_mlflow:\n            experiment_name = 'Random_Forest_Training'\n            run_name = 'Random_Forest_Cleaning'\n            \n            mlflow.set_experiment(experiment_name)\n            mlflow.start_run(run_name=run_name)\n\n            mlflow.log_param(\"cat_cols_handling\", \"mode\")\n            mlflow.log_param(\"num_cols_handling\", \"median\")\n            mlflow.log_param(\"dropped_cols_threshold\", self.null_threshold)\n            mlflow.log_param(\"dropped_columns\", self.to_drop)\n\n            mlflow.end_run()\n        \n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n\n        # Drop columns identified during fit\n        X_transformed = X_transformed.drop(columns=self.to_drop, errors='ignore')\n\n        # Fill WOE columns\n        for col in self.woe_columns:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.woe_columns_fill_na.get(col))\n\n        # Fill one-hot columns\n        for col in self.one_hot_columns:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.one_hot_columns_fill_na.get(col))\n\n        # Fill numeric columns\n        for col in self.num_cols:\n            if col in X_transformed.columns:\n                X_transformed[col] = X_transformed[col].fillna(self.num_cols_fill_na.get(col))\n\n        return X_transformed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:03.423485Z","iopub.execute_input":"2025-04-30T15:13:03.423822Z","iopub.status.idle":"2025-04-30T15:13:03.436715Z","shell.execute_reply.started":"2025-04-30T15:13:03.423799Z","shell.execute_reply":"2025-04-30T15:13:03.435498Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport mlflow\n\nclass FeatureEngineering(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, woe_columns=None, one_hot_columns=None, woe_mappings=None, woe_columns_fill_na=None, log_mlflow=False):\n        self.woe_columns = woe_columns\n        self.one_hot_columns = one_hot_columns\n        self.woe_mappings = woe_mappings\n        self.woe_columns_fill_na = woe_columns_fill_na\n        self.log_mlflow = log_mlflow\n\n    def fit(self, X, y=None):\n        # Assign default dicts if None (safe to do here)\n        self.woe_mappings_ = self.woe_mappings or {}\n        self.woe_columns_fill_na_ = self.woe_columns_fill_na or {}\n\n        # Optional: make sure columns exist\n        self.woe_columns_ = [col for col in self.woe_columns if col in X.columns]\n        self.one_hot_columns_ = [col for col in self.one_hot_columns if col in X.columns]\n\n        # Log to MLflow\n        if self.log_mlflow:\n            experiment_name = \"Random_Forest_Training\"\n            run_name = \"Random_Forest_Feature_Engineering\"\n            mlflow.set_experiment(experiment_name)\n            with mlflow.start_run(run_name=run_name):\n                mlflow.log_param(\"woe_columns\", self.woe_columns_)\n                mlflow.log_param(\"one_hot_columns\", self.one_hot_columns_)\n\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n\n        # WOE encoding\n        for col in self.woe_columns_:\n            mapping = self.woe_mappings_.get(col, {})\n            default_val = mapping.get(self.woe_columns_fill_na_.get(col), 0)\n            new_col = f'{col}_woe'\n            X_transformed[new_col] = X_transformed[col].map(mapping).fillna(default_val)\n            X_transformed.drop(columns=col, inplace=True)\n\n        # One-hot encoding\n        X_transformed = pd.get_dummies(\n            X_transformed, \n            columns=self.one_hot_columns_, \n            drop_first=True, \n            dummy_na=True,\n            dtype=int\n        )\n\n        return X_transformed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:03.438048Z","iopub.execute_input":"2025-04-30T15:13:03.438398Z","iopub.status.idle":"2025-04-30T15:13:03.466193Z","shell.execute_reply.started":"2025-04-30T15:13:03.438368Z","shell.execute_reply":"2025-04-30T15:13:03.465067Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"class FeatureSelection(BaseEstimator, TransformerMixin):\n    def __init__(self, model, correlation_threshold=0.8, n_features_to_select=150, log_mlflow=False):\n        self.model = model\n        self.correlation_threshold = correlation_threshold\n        self.n_features_to_select = n_features_to_select\n        self.log_mlflow = log_mlflow\n\n    def fit(self, X, y=None):\n        # Step 1: Remove highly correlated features\n        corr_matrix = X.corr().abs()\n        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n        self.to_drop = [column for column in upper.columns if any(upper[column] > self.correlation_threshold)]\n    \n        # Step 2: Run RFE to select top N features\n        self.rfe = RFE(self.model, n_features_to_select=self.n_features_to_select)\n        self.rfe.fit(X, y)\n    \n        all_rfe_features = X.columns[self.rfe.support_].tolist()\n    \n        # Step 3: Final selected features = RFE features minus highly correlated\n        self.selected_features = [col for col in all_rfe_features if col not in self.to_drop]\n    \n        # Step 4: Log to MLflow if enabled\n        if self.log_mlflow:\n            experiment_name = 'Random_Forest_Training'\n            run_name = 'Random_Forest_Feature_Selection'\n            \n            mlflow.set_experiment(experiment_name)\n            mlflow.start_run(run_name=run_name)\n            \n            mlflow.log_param(\"RFE_all_features\", all_rfe_features)\n            mlflow.log_param(\"Highly_correlated_dropped\", self.to_drop)\n            mlflow.log_param(\"Selected_features\", self.selected_features)\n\n            mlflow.end_run()\n    \n        return self\n\n\n    def transform(self, X):\n        return X[self.selected_features]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:03.467406Z","iopub.execute_input":"2025-04-30T15:13:03.467736Z","iopub.status.idle":"2025-04-30T15:13:03.492221Z","shell.execute_reply.started":"2025-04-30T15:13:03.467714Z","shell.execute_reply":"2025-04-30T15:13:03.491150Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nimb_pipeline = ImbPipeline(steps=[\n    ('undersampler', RandomUnderSampler(random_state=42, sampling_strategy=0.5)),\n\n    ('cleaning', Cleaning(woe_columns=woe_columns, \n                          one_hot_columns=one_hot_columns, \n                          num_cols=num_cols, log_mlflow=True)),\n\n    ('feature_engineering', FeatureEngineering(woe_columns=woe_columns, \n                                               one_hot_columns=one_hot_columns, log_mlflow=True)),\n\n    ('feature_selection', FeatureSelection(model=GradientBoostingClassifier(\n                                                random_state=42\n                                            ), n_features_to_select=150, log_mlflow=True)),\n\n    ('scaler', StandardScaler()),\n\n    ('classifier', GradientBoostingClassifier(\n        random_state=42\n    ))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:03.493315Z","iopub.execute_input":"2025-04-30T15:13:03.493681Z","iopub.status.idle":"2025-04-30T15:13:03.514516Z","shell.execute_reply.started":"2025-04-30T15:13:03.493649Z","shell.execute_reply":"2025-04-30T15:13:03.513328Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Model_v1**","metadata":{}},{"cell_type":"code","source":"imb_pipeline.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:13:12.544862Z","iopub.execute_input":"2025-04-30T15:13:12.545441Z","execution_failed":"2025-04-30T19:14:35.919Z"}},"outputs":[{"name":"stdout","text":"🏃 View run Random_Forest_Cleaning at: https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/8/runs/f5ed8380b5ee40f7b5a08817341dbdd2\n🧪 View experiment at: https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/8\n🏃 View run Random_Forest_Feature_Engineering at: https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/8/runs/5c28b867e26640a492e90085c31c15fa\n🧪 View experiment at: https://dagshub.com/nkikn21/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/8\n","output_type":"stream"},{"name":"stderr","text":"invalid value encountered in greater\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"experiment_name = 'Gradient_Boosting_Training'\nrun_name = 'Model_v1'\n\nmlflow.set_experiment(experiment_name)\nmlflow.start_run(run_name=run_name)\n\n# mlflow.log_metric(\"n_estimators\", auc_score)\n# mlflow.log_metric(\"max_depth\", f1_score_val)\n# mlflow.log_metric(\"learning_rate\", precision_score_val)\n\nmlflow.sklearn.log_model(imb_pipeline, \"Gradient_Boosting_pipeline\")\n\n# Train the model\n# imb_pipeline.fit(X_train, y_train)\n\n# Log metrics (e.g., AUC, F1-score, etc.)\ny_pred = imb_pipeline.predict(X_val)\ny_pred_proba = imb_pipeline.predict_proba(X_val)[:, 1]\n\nauc_score = roc_auc_score(y_val, y_pred_proba)\nf1_score_val = f1_score(y_val, y_pred)\nprecision_score_val = precision_score(y_val, y_pred)\nrecall_score_val = recall_score(y_val, y_pred)\n\nmlflow.log_metric(\"AUC\", auc_score)\nmlflow.log_metric(\"F1_Score\", f1_score_val)\nmlflow.log_metric(\"Precision\", precision_score_val)\nmlflow.log_metric(\"Recall\", recall_score_val)\n\n# Log model parameters\nmlflow.log_param(\"RandomUnderSampler_Sampling_Strategy\", 0.5)\nmlflow.log_param(\"Classifier\", \"XGBClassifier\")\n\nmlflow.end_run()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-30T19:14:35.920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}